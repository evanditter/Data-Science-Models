{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Classification </h1>\n",
    "<h3 align=\"center\"> Evan Ditter </h3>\n",
    "<h3 align=\"center\">March 4, 2019</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this lab I will analyze the question: **Can you predict who would be interested in buying a caravan insurance policy and give an explanation**. This question is explored through classification using bagging, booting and random forests of data collected on the customerbase for an insurance company's \"caravan insurance\" policy. This can be viewed in more detail in the models section.\n",
    "\n",
    "**References and Sources:**\n",
    "* Data sourced from: https://www.kaggle.com/uciml/caravan-insurance-challenge/version/1\n",
    "*P. van der Putten and M. van Someren (eds) . CoIL Challenge 2000: The Insurance Company Case. Published by Sentient Machine Research, Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000.*\n",
    "* Referenced: https://github.com/jayanttikmani/cross-sellingCaravanInsuranceUsingDataMining\n",
    "* Code referenced: https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/\n",
    "* Code referenced: https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/\n",
    "* Code refernced: https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**Definitions**\n",
    "* **Under-sampling** - The selection of fewer samples from a specific class than another for the creation of a model. This allows that class to be less heavily weighted than some other class.\n",
    "* **Over-sampling** - The selection of more samples from a specific class than another for the creation of a model. This allows that class to be more heavily weighted than some other class.\n",
    "* **SMOTE** - Synthetic Minority Over-sampling TechniquE is an over-samping method by which a dataset may help weight a factor in a dataset by creating synthetic datapoints based on real observations.\n",
    "\n",
    "As stated at the data source: \"this data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was collected to answer the following question: Can you predict who would be interested in buying a caravan insurance policy and give an explanation why?\"(P. van der Putten et al). As stated in the references, one can download the utilized data set from https://www.kaggle.com/uciml/caravan-insurance-challenge/version/1. The meaning of columns can also be taken from this link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>CARAVAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN  MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  \\\n",
       "0  train       33         1        3         2         8       0       5   \n",
       "1  train       37         1        2         2         8       1       4   \n",
       "2  train       37         1        2         2         8       0       4   \n",
       "3  train        9         1        3         3         3       2       3   \n",
       "4  train       40         1        4         2        10       1       4   \n",
       "\n",
       "   MGODOV  MGODGE   ...     APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  \\\n",
       "0       1       3   ...            0        0        0       1        0   \n",
       "1       1       4   ...            0        0        0       1        0   \n",
       "2       2       4   ...            0        0        0       1        0   \n",
       "3       2       4   ...            0        0        0       1        0   \n",
       "4       1       4   ...            0        0        0       1        0   \n",
       "\n",
       "   APLEZIER  AFIETS  AINBOED  ABYSTAND  CARAVAN  \n",
       "0         0       0        0         0        0  \n",
       "1         0       0        0         0        0  \n",
       "2         0       0        0         0        0  \n",
       "3         0       0        0         0        0  \n",
       "4         0       0        0         0        0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"caravan-insurance-challenge.csv\")\n",
    "train = df[df[\"ORIGIN\"] == \"train\"]\n",
    "test = df[df[\"ORIGIN\"] == \"test\"]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>CARAVAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>test</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>test</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>test</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ORIGIN  MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  \\\n",
       "5822   test       33         1        4         2         8       0       6   \n",
       "5823   test        6         1        3         2         2       0       5   \n",
       "5824   test       39         1        3         3         9       1       4   \n",
       "5825   test        9         1        2         3         3       2       3   \n",
       "5826   test       31         1        2         4         7       0       2   \n",
       "\n",
       "      MGODOV  MGODGE   ...     APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  \\\n",
       "5822       0       3   ...            0        0        0       1        0   \n",
       "5823       0       4   ...            0        0        0       1        0   \n",
       "5824       2       3   ...            0        0        0       1        0   \n",
       "5825       2       4   ...            0        0        0       1        0   \n",
       "5826       0       7   ...            0        0        0       1        0   \n",
       "\n",
       "      APLEZIER  AFIETS  AINBOED  ABYSTAND  CARAVAN  \n",
       "5822         0       0        0         0        0  \n",
       "5823         0       0        0         0        1  \n",
       "5824         0       0        0         0        0  \n",
       "5825         0       0        0         0        0  \n",
       "5826         0       0        0         0        0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set, seen above consists of 9821 observations from a training and test set. Observations can be differentiated by their value in the \"ORIGIN\" column. All of the various columns have meanings that can be looked up at the aforementioned link above. The last column, which reads 1 or 0 where 1 indicates purchased insurances and 0 indicates no purchase of insurance. Only the training data will be used for model creation and fitness will be tested against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not purchased 5474\n",
      "Purchased: 348\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_count = train.CARAVAN.value_counts()\n",
    "print('Not purchased', target_count[0])\n",
    "print('Purchased:', target_count[1])\n",
    "target_count.plot(kind='bar', title='Count (Insurance Purchased)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see by this bar graph, this dataset is very unbalanced, so several models will be generated to account for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Due to the unbalanced nature of this dataset, I must sample so that I train on approximately equal fail and success rates. The tables below are in the form \n",
    "\n",
    "true negative   false positive<br/>\n",
    "false negative   true positive\n",
    "\n",
    "### Bagging\n",
    "\n",
    "**Unbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_test = test['CARAVAN']\n",
    "train_0 = train[train['CARAVAN'] == 0]\n",
    "train_1 = train[train['CARAVAN'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.925\n",
      "[[3682   80]\n",
      " [ 220   18]]\n"
     ]
    }
   ],
   "source": [
    "# Formatting\n",
    "x_train = train.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unbalanced data seems to predict mostly correct, however this is simply due to the fact that almost no positives are ever estimated, this model is only valid if no one wants insurance.\n",
    "\n",
    "**Under-sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.70025\n",
      "[[2672 1090]\n",
      " [ 109  129]]\n"
     ]
    }
   ],
   "source": [
    "# Undersampling\n",
    "train_0_under = train_0.sample(target_count[1])\n",
    "train_under = pd.concat([train_0_under, train_1], axis=0)\n",
    "\n",
    "# Formatting\n",
    "x_train = train_under.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train_under['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, bootstrap undersampling causes a large number of false positives, but steers relatively clear of false positives. This model can work, but has a very bad accuracy.\n",
    "\n",
    "**Over-sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.89775\n",
      "[[3561  201]\n",
      " [ 208   30]]\n"
     ]
    }
   ],
   "source": [
    "# Oversampling\n",
    "train_1_over = train_1.sample(target_count[0], replace=True)\n",
    "train_over = pd.concat([train_1_over, train_0], axis=0)\n",
    "\n",
    "# Formatting\n",
    "x_train = train_over.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train_over['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method resulted in a mix of false positive and negatives while producing almost no true positives. This model is seemingly better, but still does not very accurately estimate.\n",
    "\n",
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9185\n",
      "[[3649  113]\n",
      " [ 213   25]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "\n",
    "x_train = train.drop([\"ORIGIN\", \"CARAVAN\"], axis = 1)\n",
    "y_train = train[\"CARAVAN\"]\n",
    "\n",
    "x_sm, y_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_sm, y_sm)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is comparable to oversampling, but has a lower rate of false positives, making this a slightly more robust model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "I will now run Random Forest to make this estimation. The number of predictors used in all cases is 10.\n",
    "\n",
    "**Unbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_test = test['CARAVAN']\n",
    "train_0 = train[train['CARAVAN'] == 0]\n",
    "train_1 = train[train['CARAVAN'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.928\n",
      "[[3698   64]\n",
      " [ 224   14]]\n"
     ]
    }
   ],
   "source": [
    "# Formatting\n",
    "x_train = train.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = RandomForestClassifier(n_estimators = 10)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced random forests create a reasonable model, but still suffers against false positives far outweighing true positives.\n",
    "\n",
    "**Under-sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.693\n",
      "[[2638 1124]\n",
      " [ 104  134]]\n"
     ]
    }
   ],
   "source": [
    "# Undersampling\n",
    "train_0_under = train_0.sample(target_count[1])\n",
    "train_under = pd.concat([train_0_under, train_1], axis=0)\n",
    "\n",
    "# Formatting\n",
    "x_train = train_under.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train_under['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = RandomForestClassifier(n_estimators = 10)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of false positives generated by undersampling is, yet again, immense. This is problematic for predictions. \n",
    "\n",
    "**Over-sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.91525\n",
      "[[3634  128]\n",
      " [ 211   27]]\n"
     ]
    }
   ],
   "source": [
    "# Oversampling\n",
    "train_1_over = train_1.sample(target_count[0], replace=True)\n",
    "train_over = pd.concat([train_1_over, train_0], axis=0)\n",
    "\n",
    "# Formatting\n",
    "x_train = train_over.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train_over['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = RandomForestClassifier(n_estimators = 10)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are only slightly better than bagging's over-sample model. The issue of false positives outweighting true is still a large issue.\n",
    "\n",
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9245\n",
      "[[3684   78]\n",
      " [ 224   14]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "\n",
    "x_train = train.drop([\"ORIGIN\", \"CARAVAN\"], axis = 1)\n",
    "y_train = train[\"CARAVAN\"]\n",
    "\n",
    "x_sm, y_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 10)\n",
    "model.fit(x_sm, y_sm)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE method in random forests suffers the least from the issue of false positives, but still fails to accurately estimate whether someone will buy caravan insurance with a still huge number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "**Unbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_test = test['CARAVAN']\n",
    "train_0 = train[train['CARAVAN'] == 0]\n",
    "train_1 = train[train['CARAVAN'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.93875\n",
      "[[3751   11]\n",
      " [ 234    4]]\n"
     ]
    }
   ],
   "source": [
    "# Formatting\n",
    "x_train = train.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced boosting provides very few positives at all, with only 4 true positives this method essentially does not estimate at all.\n",
    "\n",
    "**Under-sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6725\n",
      "[[2551 1211]\n",
      " [  99  139]]\n"
     ]
    }
   ],
   "source": [
    "# Undersampling\n",
    "train_0_under = train_0.sample(target_count[1])\n",
    "train_under = pd.concat([train_0_under, train_1], axis=0)\n",
    "\n",
    "# Formatting\n",
    "x_train = train_under.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train_under['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The huge number of false positives in this model greatly offset the higher number of true positives than false negatives. This will result in almost all positive results actually being negative.\n",
    "\n",
    "**Over-sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7175\n",
      "[[2738 1024]\n",
      " [ 106  132]]\n"
     ]
    }
   ],
   "source": [
    "# Oversampling\n",
    "train_1_over = train_1.sample(target_count[0], replace=True)\n",
    "train_over = pd.concat([train_1_over, train_0], axis=0)\n",
    "\n",
    "# Formatting\n",
    "x_train = train_over.drop(['ORIGIN', 'CARAVAN'], axis = 1)\n",
    "y_train = train_over['CARAVAN']\n",
    "\n",
    "# Model Creation\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same issue persists in oversampling as was in under. This seems to be a pervasive problem with boosting.\n",
    "\n",
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.93875\n",
      "[[3751   11]\n",
      " [ 234    4]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "\n",
    "x_train = train.drop([\"ORIGIN\", \"CARAVAN\"], axis = 1)\n",
    "y_train = train[\"CARAVAN\"]\n",
    "\n",
    "x_sm, y_sm = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy: \", model.score(x_test, y_test))\n",
    "\n",
    "# Code to generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote causes similar results to unbalanced in this case, greater complexity for no real result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question this lab intended to answer was: Can you predict who would be interested in buying a caravan insurance policy and give an explanation. Based on this result I would say that you kind of can. None of the above models produces more true positives than false negatives and false positives. This is an issue in that targeted advertizing is guaranteedly going to miss more or hit more than the people who actually want the insurance. However, depending on the overheads for advertizing, one could argue that false positives are relatively inconsequential. Based on this under or over-sampling using boosting could be said to predict well enough to warrant use of this method to advertise insurance. Further work could be done with a cost analysis of advertizing against the false positive rate.\n",
    "\n",
    "One thing that can be noticed, is that the methods of data normalization seemed to have far more consistant results across modeling methods than the results of each modeling method had across data normallization. This would indicate that it does not matter as much how one creates a model as it does the data one feeds into said model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
